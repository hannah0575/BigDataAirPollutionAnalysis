--- 

title: "AirPolDataAnalysis" 

author: "Hannah Beaton" 

date: "07/07/2022" 

output: html_document 

--- 

#1.Load packages 

```{r} 

#install.packages("Rbeast")  

#install.packages("bfast")  

#install.packages("tidyverse")  

#install.packages("ggplot2")  

#install.packages("dpylr")  

#install.packages("lubridate")  

#install.packages("tidyr")  
  
#install.packages("sf") 

#install.packages("vegan")

#install.packages("dygraphs") 

#install.packages("xts") 

#install.packages("data.table")

#install.packages("factoextra")


library("Rbeast")  

library("tidyverse")  
  
library("ggplot2")  

library(dplyr)  

library(tidyr)  

library(sf) 

library("lubridate") 

library(reshape2) 

library(vegan)

library(xts) 

library(dygraphs) 

library(data.table)

library(leaflet)

library("factoextra")

``` 


#1.1. Load Site Data 
```{r} 

#set working directory  
setwd("~/Desktop/BEES3041/AirPollAnalysis")


#Load Site Air pollution Data   

PolSite1 <- read.csv("Data/AirPolData/AirPol_24hr_Site1.csv")  
PolSite2 <- read.csv("Data/AirPolData/AirPol_24hr_Site2.csv")  
PolSite3 <- read.csv("Data/AirPolData/AirPol_24hr_Site3.csv")  
PolSite4 <- read.csv("Data/AirPolData/AirPol_24hr_Site4.csv")  
PolSite5 <- read.csv("Data/AirPolData/AirPol_24hr_Site5.csv")  

``` 

#2.Clean and Combine Site Data 
###2.1. Split Pollutants, Sites and Dates into distinguished columns to organise data frames corresponding to each pollutant of interest 
```{r} 

PollSites <- cbind(PolSite1, PolSite2, PolSite3, PolSite4, PolSite5) 

#break into a list by pollutants with column pollutant split from column site  

#df with the names 

time_by_poll = list() 

for (colname in colnames(PollSites)) { 

# Split the column headers on the dots 

  parts = unlist(strsplit(colname, ".", fixed=TRUE)) 

  # message(parts) 

  site = parts[1] 

  if (length(parts) == 2) { 

    pollutant = parts[2] 

  } 

# reassemble with Site (1) and Pollutants (2) 

  else { 

    pollutant = paste (parts[2], parts[3], sep=".") 

  } 


  #  create data frame 

  if (is.null(time_by_poll[[pollutant]])) { 

    dates = lubridate::dmy(PollSites[["Date"]]) #makes "Date" a date class 

    time_by_poll[[pollutant]] = data.frame (Date = dates) 

  } else { 
    time_by_poll[[pollutant]][site] = PollSites[[colname]] 
  } 

} 

#output now gives a data frame for each of the 8 pollutants for every corresponding site and date  

#Pollutants data frame = SO2, NO, NO2, OZONE, PM2.5, PM10, CO, H3  

#View(time_by_poll$"OZONE") 

``` 


#2.2 Data Screening 
###Omit insufficient data recordings and incomplete site and pollution analysis 
```{r} 

#Use TS to look at the general trends of the data at each site to determine which have sufficient data  
##site data with < 70% of pollutant recordings (recording majority 0) between 2012 and 2022 are omitted  
###Manually screen data for data recording sufficiency
####Repeat for all site in all pollutants 


ts(time_by_poll$PM2.5$LIDCOMBE) 

  plot.ts(time_by_poll$PM2.5$LIDCOMBE)  

#View(time_by_poll$NO2)
#View(time_by_poll$OZONE)
   
  ts(time_by_poll$NO$LIDCOMBE) 

  plot.ts(time_by_poll$NO$LIDCOMBE)  
   

  ts(time_by_poll$NO2$LIDCOMBE) 

  plot.ts(time_by_poll$NO2$LIDCOMBE)  

   
  ts(time_by_poll$OZONE$LIDCOMBE) 

  plot.ts(time_by_poll$OZONE$LIDCOMBE) 


  ts(time_by_poll$PM10$LIDCOMBE) 

  plot.ts(time_by_poll$PM10$LIDCOMBE)  


#GOOD DATA -  OZONE, NO, NO2,PM10 - 4 POLLUTANTS / 21 LOCATIONS  

##Wollongong  
##MUSWELLBROOK 
##SINGLETON 
##CAMBERWELL 
##WAGGAWAGGANORTH 
##RICHMOND 
##CAMDEN 
##CHULLORA 
##EARLWOOD 
##WALLSEND 
##BERESFIELD 
##BARGO  
##BRINGELLY  
##PROSPECT 
##STMARYS 
##OAKDALE 
##RANDWICK 
##ROZELLE 
##NEWCASTLE 
#KEMBLAGRANGE 
#ALBIONPARKSOUTH 
  
### BAD Data ###  

#OMIT (CO, SO2, H3, PM2.5)  

###TAMWORTH#### 
###NARRABRI### 
####GUNNEDAH### 
####ARMIDALE###
####ORANGE### 
####PORTMACQUARIE### 
####COFFSHARBOUR### 
####MORISSET - one of the worst - good to show  
###ALBURY - NO2 one of the worst  
###MERRIWA### 
####LIVERPOOL#### 
####BRADFIELDHIGHWAY#### 
####KATOOMBA### 
###GOULBURN### 
###CAMMERAY#### 
###PARRAMATTANORTH### 
####ROUSEHILL### 
###PENRITH### 
###MACARTHUR#### 
####CARRINGTON#### 
###STOCKTON#### 
###MAYFIELD### 
###MACQUARIEPARK### 
###LIDCOMBE##### 
``` 

#2.3 Filter data to select only target sites and target pollutants 
###Create new data frame with target sites to use for the rest of the analysis 
###tSiteList for BEAST Plotting 
```{r}

#Create Data Frames and List with just Target Sites 
###Make data frames with key Target sites 
TargetSites <- c('Date', 'WOLLONGONG', 'MUSWELLBROOK', 'SINGLETON', 'CAMBERWELL', 'WAGGAWAGGANORTH', 'RICHMOND', 'CAMDEN', 'CHULLORA', 'EARLWOOD', 'WALLSEND', 'BERESFIELD', 'BARGO', 'BRINGELLY', 'PROSPECT', 'STMARYS', 'OAKDALE', 'RANDWICK', 'ROZELLE', 'NEWCASTLE', 'KEMBLAGRANGE', 'ALBIONPARKSOUTH')

tNO2 <- (time_by_poll$NO2[, (colnames(time_by_poll$NO2) %in% c(TargetSites))])

tPM10 <- (time_by_poll$PM10[, (colnames(time_by_poll$PM10) %in% c(TargetSites))])

tOZONE <- (time_by_poll$OZONE[, (colnames(time_by_poll$OZONE) %in% c(TargetSites))])

###List target sites 

tSiteList <- list(tNO2, tPM10, tOZONE)

tSiteList = list(
  "NO2" = tSiteList[[1]],
  "PM10" = tSiteList[[2]],
  "OZONE" = tSiteList[[3]]
)

#View(tSiteList)
#View(tSiteList$OZONE)

```

#2.4  Load Point file and Clean to target sites 
```{r}

Pointfile <- read.csv("~/Desktop/BEES3041/AirPollAnalysis/Data/PointFile.csv") 

#View(Pointfile)

#Make point file for only Target Sites 

TargetSites <- c('Date', 'WOLLONGONG', 'MUSWELLBROOK', 'SINGLETON', 'CAMBERWELL', 'WAGGAWAGGANORTH', 'RICHMOND', 'CAMDEN', 'CHULLORA', 'EARLWOOD', 'WALLSEND', 'BERESFIELD', 'BARGO', 'BRINGELLY', 'PROSPECT', 'STMARYS', 'OAKDALE', 'RANDWICK', 'ROZELLE', 'NEWCASTLE', 'KEMBLAGRANGE', 'ALBIONPARKSOUTH')

TargetPoint <- Pointfile[apply(Pointfile,1,function(x) {any(c(TargetSites) %in% x)}),]
TargetPoints <- TargetPoint[-103,]

#View(TargetPoints)

```

#Merge Point file and tSitelist Data frames
###Matches pollution and the site variables 
###Good for plotting relationships 
```{r}

# Flip data tables from wide to long 
OzoneTest.long <- melt(tSiteList$OZONE,
  id.vars = c("Date"),
  measure.vars = c('WOLLONGONG', 'WAGGAWAGGANORTH', 'RICHMOND', 'CAMDEN', 'CHULLORA', 'EARLWOOD', 'WALLSEND', 'BERESFIELD', 'BARGO', 'BRINGELLY', 'PROSPECT', 'STMARYS', 'OAKDALE', 'RANDWICK', 'ROZELLE', 'NEWCASTLE', 'KEMBLAGRANGE', 'ALBIONPARKSOUTH'),
  variable.name = "Sites", value.name = "Ozone"
)
#View(OzoneTest.long)

summary(OzoneTest.long$Sites)

#PM10
PMTest.long <- melt(tSiteList$PM10,
  id.vars = c("Date"),
  measure.vars = c('WOLLONGONG', 'WAGGAWAGGANORTH','MUSWELLBROOK', 'SINGLETON', 'CAMBERWELL', 'RICHMOND', 'CAMDEN', 'CHULLORA', 'EARLWOOD', 'WALLSEND', 'BERESFIELD', 'BARGO', 'BRINGELLY', 'PROSPECT', 'STMARYS', 'OAKDALE', 'RANDWICK', 'ROZELLE', 'NEWCASTLE', 'KEMBLAGRANGE', 'ALBIONPARKSOUTH'),
  variable.name = "Sites", value.name = "PM10"
)

#View(PMTest.long)

summary(PMTest.long$Sites)

#NO2

NO2Test.long <- melt(tSiteList$NO2,
  id.vars = c("Date"),
  measure.vars = c('WOLLONGONG', 'WAGGAWAGGANORTH','MUSWELLBROOK', 'SINGLETON', 'RICHMOND', 'CAMDEN', 'CHULLORA', 'EARLWOOD', 'WALLSEND', 'BERESFIELD', 'BARGO', 'BRINGELLY', 'PROSPECT', 'STMARYS', 'OAKDALE', 'RANDWICK', 'ROZELLE', 'NEWCASTLE', 'KEMBLAGRANGE', 'ALBIONPARKSOUTH'),
  variable.name = "Sites", value.name = "NO2"
)

#View(NO2Test.long)

summary(NO2Test.long$Sites)

#Change Target point 'Site' to 'Sites
TARGETpoints <- rename(TargetPoints, "Sites" = "Site") 

View(TARGETpoints) 


### Merge the each pollutant to the Target Point Data  

TargetNO2 <- left_join(NO2Test.long, TARGETpoints, by = "Sites")
#View(TargetNO2)

TargetOZONE <- left_join(OzoneTest.long, TARGETpoints, by = "Sites")
#View(TargetOZONE)  

TargetPM <- left_join(PMTest.long, TARGETpoints, by = "Sites")
#View(TargetPM)  
      
TARGETDATA <- list(TargetPM, TargetOZONE, TargetNO2)

TARGETDATA = list(
  "PM10" = TARGETDATA[[1]],
  "OZONE" = TARGETDATA[[2]],
  "NO2" = TARGETDATA[[3]]
)

#View(TARGETDATA)

```

#3. Visualisation of data 
### 3.1. Plot the timeseries data for target locations and pollutants 
```{r} 

#plot the time series data to in interactive time plot  

#Plot multiple locations on a single dygraph
## Find means that vary greatest to plot 
colMeans(tSiteList$OZONE[sapply(tSiteList$OZONE, is.numeric)]) 

###WAGGAWAGGANORTH = 0.1955185
###OAKDALE 2.4319698
###BERESFIELD =  1.4877280 
###WOLLONGONG = 1.8233194

Ozone.sites = cbind(WOLLONGONG = ts(data = tSiteList$OZONE$WOLLONGONG, start = c(2012,1), frequency = 12), 

                    OAKDALE = ts(data = tSiteList$OZONE$OAKDALE, start = c(2012,1), frequency = 12), 

                    WAGGAWAGGANORTH = ts(data = tSiteList$OZONE$WAGGAWAGGANORTH, start = c(2012,1), frequency = 12), 

                    BERESFIELD = ts(data = tSiteList$OZONE$BERESFIELD, start = c(2012,1), frequency = 12)) 

dygraph(data = Ozone.sites,  

        main = "Ozone pollution") %>% 

  dySeries(name = "WOLLONGONG", stepPlot = FALSE, color = "red") %>% 

  dyGroup(c("OAKDALE", "WAGGAWAGGANORTH", "BERESFIELD"), drawPoints = FALSE,  

          color = c("blue", "green", "black")) %>% 

  dyRoller(rollPeriod = 12)%>% 
  
  dyRangeSelector() 

### Can be used to compare means of industrial / Urban / Rural sites for each pollutant 

```


#3.1.2 Looking at the average pollution trends over time within each region 
##Creating time series regional trends over time  gifs 
```{r}

# Manually screen and watch for each pollutant (OZONE, PM10, NO2)


#tiff("PM10_2012-2022.tiff")

AniPM <- ggplot(
  TARGETDATA$PM10,
  aes(Date, PM10, group = Region, color = factor(Region))
  ) +
  geom_line() +
  scale_color_viridis_d() +
  labs(x = "Years", y = "PM10 concentration") +
  theme(legend.position = "right") 



#dev.off()


PMAnimate <- AniPM + transition_reveal(Date)

PMAnimate

#Save animation as .gif
anim_save("NO2_2012_22.gif")


```


### 3.2. Map Sensor Data Points 
```{r}

# Map Points on the map first using Target Points 

leaflet() %>%
  addTiles()

leaflet() %>%
  addTiles() %>%
  addScaleBar() %>%
  setView(lng = 151.209, lat = -33.868, zoom = 5.5) %>%
  addMiniMap()

base <- leaflet() %>%
  addTiles() %>%
  addScaleBar() %>%
  setView(lat = mean(TargetPoints$Lat), lng = mean(TargetPoints$Long), zoom = 6)

base %>% addMarkers(
  lng = TargetPoints$Long, lat = TargetPoints$Lat,
  label = TargetPoints$Site
) 

#Colour the clusters 
cols <- c("darkred", "darkgreen", "orange")
color_function <- colorFactor(cols, domain = NULL)

base %>%
  addCircleMarkers(
    lng = TargetPoints$Long, lat = TargetPoints$Lat,
    color = color_function(TargetPoints$Region),
    label = TargetPoints$Region
  ) %>%
  addLegend(pal = color_function, values = TargetPoints$Region)


```


###3.2.1 Map the average concentration of air pollution over time at different target sites
```{r}

#Boxplot? 

View(TARGETDATA$PM10)

# TRANSFOMRATIONS - to see if the data better reflects assumptions 
## LOG
TargetPmLog<- log(TARGETDATA$PM10$PM10)+1
## SQRT
TARGETDATA$PM10$PMsqrt=sqrt(TARGETDATA$PM10$PM10)

```


#3.3 PCA Analysis 
### Computing target sites and pollutants to see if sites clump into Rural/Urban/Industrial 
```{r}
#Colour by TargetSites$Region

## Basic biplots

biplot(Pm10PCA,
       col=c("red", "blue"),
       cex=c(0.01, 0.5))


NO2PCAdf = tSiteList$NO2
NO2PCA = princomp(NO2PCAdf[2:ncol(NO2PCAdf)])
plot(NO2PCA)
biplot(NO2PCA,
       col= as.factor( ),
       cex=c(0.01, 0.5)
       )


PmPCAdf = tSiteList$PM10
Pm10PCA = princomp(PmPCAdf[2:ncol(PmPCAdf)])
plot(Pm10PCA)

OzPCAdf = tSiteList$OZONE
Oz10PCA = princomp(OzPCAdf[2:ncol(OzPCAdf)])
plot(Oz10PCA)


## PCA highlighting groups of highest contributing values 
# THis should correlate between urban /rural and / urban regions 

pcadf = Oz10PCA, Pm10PCA, NO2PCA

for (pca in pcadf){
  fviz_pca_var(pcadf,
               col.var = "cos2",
               gradient.cols = c("#E7B800","#00AFBB","#FC4E07"), 
               repel = TRUE
             ) 
}


#NO2
fviz_pca_var(NO2PCA, col.var = "cos2",
             gradient.cols = c("#E7B800","#00AFBB","#FC4E07"), 
             repel = TRUE # Avoid text overlapping
             )

#PM10
fviz_pca_var(PmPCA, col.var = "cos2",
             gradient.cols = c("#E7B800","#00AFBB","#FC4E07"), 
             repel = TRUE # Avoid text overlapping
             )
#OZONE
#tiff("OZONE_PCA.tiff")

fviz_pca_var(Oz10PCA, col.var = "cos2",
             gradient.cols = c("#E7B800","#00AFBB","#FC4E07"), 
             repel = TRUE # Avoid text overlapping
             )

#dev.off()



##HOW TO GROUP DATA BY REGION???? DONT KNOW YET 
fviz_pca_ind(Pm10PCA,
             geom.ind = "point", # show points only (nbut not "text")
             col.ind =  TARGETDATA$PM10$Region (???) , # color by groups
             palette = c("#00AFBB", "#E7B800", "#FC4E07"),
             addEllipses = TRUE, # Concentration ellipses
             legend.title = "Groups"
             )


```


#4. Rbeast Irregular 
### Plotting the decomposition and change points of Pollution and Site data using the package (Beast) 
```{r}

# Zhao Rbeast Example - Run to manipluate to Air_poll Data 
# Monthly data Example 
df    = read.csv('https://github.com/zhaokg/Rbeast/raw/master/R/SampleData/pm10_1658112168.csv',header=FALSE,skip=3)

dates = as.Date(df[,1], "%d/%m/%Y")  # the 1st col is dates
Y     = df[,2:ncol(df)]              # the rest are PM10 data for the several sample sites
                                  # e.g., Y[,1] for the first region (WOLLONGONG)

o = beast.irreg(log(Y[,1]),time=dates,deltat=1/12, freq=12, tseg.min=3, sseg.min=6)
plot(o)

# log(Y[,1]) :  Log-transformation may help if data is skewed bcz the BEAST model 
                assumes Gaussian errors;
# time=dates :  Use the 'time' arg to supply the times of individual data points.
               Alternatively, the `beast123' function also handles date strings of different formats
# deltat=1/12:  Aggregate the daily time series into a regular one at the interval 
                of 1 month=1/12 year
# freq=12 :    The period is 1 year, which is 12 data points (1.0/deltat=12)
# tseg.min:     The minimum trend segment length allowed in the changepoint detection is 3 data points (3 months) 
                -- the results MAY be sensitive to this parameter
# sseg.min:     The minimum seasonal segment length allowed in the changepoint detection is 6 data points (6 months) 
                -- the results MAY be sensitive to this parameter


#Daily Rbeast time series decomposition using time_by_poll Site data 
## Manually compute for each target pollutant (NO2,OZONE,PM10) 
## Manually compute for each target site (18-24)
### This allows individual data to be assessed for sites oncemore and allow invidual .tiff files to be named accordingly and exported 

### View the data frame to know which target location corresponds to each , :ncol
View(time_by_poll$OZONE)


tiff("OZONE_RICHMOND")

dates = as.Date(tSiteList$OZONE[,1], "%d/%m/%Y")  
Y     = tSiteList$OZONE[,17:ncol(tSiteList$OZONE)] #Example ncol 17 = RICHMOND (target site = TRUE)
Y[Y==0]=NA 

OZONE_RICHMOND = beast.irreg( log(Y[,1]),time=dates,  deltat = 1/365, freq=365/1,  tseg.min=30, sseg.min=180)
plot(OZONE_RICHMOND)

dev.off() 


#Create Loop... for each location and each pollutant 
### Collect the outputs (R2 & NCP for Trend & season)




```

#5. Make Point file into an SF object to begin spatial time series animation  
### Aim is to plot the pollution data concentrations over time within NSW 
#### This will then be correlated with NSW local government zoning (industrial/urban/rural)
```{r}
View(TARGETDATA)

#install.packages('gganimate')
#install.packages('gifski')
install.packages('ozmaps')
library(gganimate)
library(gifski)
library(ggplot2)
library(ozmaps)
library(sf)
#install.packages('rgdal')
#install.packages('RColorBrewer')
library(rgdal)
library(RColorBrewer)


sf_oz <- ozmap("states")
NSWmap <- ggplot(data = *** ) + geom_sf()
NSWmap
```



#6. Binomial Analysis ??? - may not be needed... 
## Computing to see if there is significant difference between sites and their air pollution concentrations 
```{r}

#Binomial GLM - Need to account for the effects surrounding daily data may have

#Show data skew 


#log transform data 



#Binomial for individual sites? Grouped site regions? 


```



#7. Load and Clean Meterological Data ?? 
### Eventually might look into the subsetting a time frame to assess impacts meterological variables have on Air Pollution 
```{r}

#Load Meteorological data  

TempHrData<- read.csv("Data/MeteorData/AirTemp/TsTemp_1hr.csv") 

HumidHrData<- read.csv("Data/MeteorData/Humidity/TsHumid_1hr.csv") 

WsHrData <- read.csv("Data/MeteorData/WindSpeed/TsWS_1hr.csv") 

  
#remove top empty row and rename columns  


#temp 

names(TempHrData) <- TempHrData[1,] 

TempHr <- TempHrData[-1,] 

colnames(TempHr)[1] <- c('Date')  

colnames(TempHr)[2] <- c('Time') 


#wind speed  

names(WsHrData) <- WsHrData[2,] 

WsHr <- WsHrData[-1,] 

WsHr <- WsHr[-1,] 


#Humidity 

names(HumidHrData) <- HumidHrData[2,] 

HumidHr <- HumidHrData[-1,] 

HumidHr <- WsHr[-1,] 

  
```



